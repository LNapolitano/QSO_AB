{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import desispec.io\n",
    "import fitsio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import modeling\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "tile='68000'\n",
    "date='20200314'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DESI_SPECTRO_REDUX=/global/cfs/cdirs/desi/spectro/redux\n",
      "env: SPECPROD=andes\n",
      "DEBUG: Read templates from /global/common/software/desi/cori/desiconda/20190804-1.3.0-spec/code/redrock-templates/master\n",
      "DEBUG: Using default redshift range -0.0050-1.6997 for rrtemplate-galaxy.fits\n",
      "DEBUG: Using default redshift range 0.0500-5.9934 for rrtemplate-qso.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-A.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-B.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-CV.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-F.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-G.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-K.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-M.fits\n",
      "DEBUG: Using default redshift range -0.0020-0.0020 for rrtemplate-star-WD.fits\n"
     ]
    }
   ],
   "source": [
    "%set_env DESI_SPECTRO_REDUX=/global/cfs/cdirs/desi/spectro/redux\n",
    "%set_env SPECPROD=andes\n",
    "reduxdir = desispec.io.specprod_root()\n",
    "\n",
    "#read-in redrock templates\n",
    "import redrock.templates\n",
    "from desispec.interpolation import resample_flux\n",
    "from desispec.resolution import Resolution\n",
    "\n",
    "templates = dict()\n",
    "for filename in redrock.templates.find_templates():\n",
    "    t = redrock.templates.Template(filename)\n",
    "    templates[(t.template_type, t.sub_type)] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get spectrum from targetid\n",
    "def get_spec(targetid,tile,date,to_print=False):\n",
    "    dirn = os.path.join(reduxdir, \"tiles\", tile, date)\n",
    "    for spectrograph in range(10):\n",
    "        fn = \"coadd-{}-{}-{}.fits\".format(spectrograph, tile, date)\n",
    "        file = os.path.join(dirn, fn)\n",
    "        fmap = fitsio.read(file, \"FIBERMAP\")\n",
    "        for i in range(500):\n",
    "            if(str(fmap['TARGETID'][i]) == targetid):\n",
    "                specnum = i\n",
    "                fnstore=fn\n",
    "                spectrographstore = spectrograph\n",
    "                if(to_print):\n",
    "                    print(fn,spectrograph,i)\n",
    "    specfn = os.path.join(dirn, fnstore)\n",
    "    specobj = desispec.io.read_spectra(specfn)\n",
    "    \n",
    "    if(\"brz\" in specobj.wave):\n",
    "        x_spc = specobj.wave[\"brz\"]\n",
    "        y_flx = specobj.flux[\"brz\"][specnum]\n",
    "        y_err=1/np.sqrt(specobj.ivar[\"brz\"][specnum])\n",
    "    #else combine into \"brz\" using helper fnc.\n",
    "    else:\n",
    "        x_spc,y_flx,y_err=quick_brz(specobj,specnum)\n",
    "    \n",
    "    return(x_spc,y_flx,y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn 'b', 'r', 'z' into 'brz'\n",
    "def quick_brz(specobj,spectrum):\n",
    "    #pull wavelength sections\n",
    "    bw=np.round(specobj.wave['b'],3)\n",
    "    rw=np.round(specobj.wave['r'],3)\n",
    "    zw=np.round(specobj.wave['z'],3)\n",
    "    \n",
    "    #find overlapping arrays in wave\n",
    "    br_overlap=np.intersect1d(bw,rw)\n",
    "    rz_overlap=np.intersect1d(rw,zw)\n",
    "\n",
    "    #find indices of overlapping regions\n",
    "    br_start=int(np.where(bw==br_overlap[0])[0])\n",
    "    br_end=int(len(bw))\n",
    "\n",
    "    rz_start=int(np.where(rw==rz_overlap[0])[0])\n",
    "    rz_end=int(len(rw))\n",
    "\n",
    "    #pull flux\n",
    "    bf=specobj.flux['b'][spectrum]\n",
    "    rf=specobj.flux['r'][spectrum]\n",
    "    zf=specobj.flux['z'][spectrum]\n",
    "    #pull error\n",
    "    be=1/np.sqrt(specobj.ivar['b'][spectrum])\n",
    "    re=1/np.sqrt(specobj.ivar['r'][spectrum])\n",
    "    ze=1/np.sqrt(specobj.ivar['z'][spectrum])\n",
    "    #turn into 'brz'\n",
    "    x_spc=np.concatenate((bw[:br_start],(bw[br_start:br_end]+rw[:br_end-br_start])/2,rw[br_end-br_start:rz_start],(rw[rz_start:rz_end]+zw[:rz_end-rz_start])/2,zw[rz_end-rz_start:]))\n",
    "    y_flx=np.concatenate((bf[:br_start],(bf[br_start:br_end]+rf[:br_end-br_start])/2,rf[br_end-br_start:rz_start],(rf[rz_start:rz_end]+zf[:rz_end-rz_start])/2,zf[rz_end-rz_start:]))\n",
    "    y_err=np.concatenate((be[:br_start],(be[br_start:br_end]+re[:br_end-br_start])/2,re[br_end-br_start:rz_start],(re[rz_start:rz_end]+ze[:rz_end-rz_start])/2,ze[rz_end-rz_start:]))\n",
    "    \n",
    "    return(x_spc,y_flx,y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MgII_Model(theta,x):\n",
    "    z,a1,a2,s1,s2,m,b=theta\n",
    "    #determine peak centers\n",
    "    m1=(z+1)*2795.5301\n",
    "    m2=(z+1)*2802.7056\n",
    "    \n",
    "    #Generate Model\n",
    "    model = m*(x-x[0]) +b + a1*np.exp((-(x-m1)**2)/(2*s1**2))+a2*np.exp((-(x-m2)**2)/(2*s2**2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likelihood fnc\n",
    "def log_likelihood(theta, x, y, yerr):\n",
    "    #generative model\n",
    "    model = MgII_Model(theta,x)\n",
    "    #error into variance\n",
    "    sigma2 = yerr ** 2\n",
    "    #Actual Likelihood fnc\n",
    "    return -0.5 * np.sum((y - model) ** 2 / sigma2 + np.log(sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior fnc, could contain more info on reasonable redshifts, heights and widths\n",
    "def log_prior(theta,z_low,z_high):\n",
    "    z,a1,a2,s1,s2,m,b=theta\n",
    "    #if -100 < a1 < 100 and  -100 < a2 < 100 and 0 < s1  and  0 < s2  and z_low < z < z_high:\n",
    "    if 0 < s1 and 0 < s2 and z_low < z < z_high:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability fnc\n",
    "def log_probability(theta, x, y, yerr, z_low, z_high):\n",
    "    lp = log_prior(theta,z_low,z_high)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation Failure: 35191251972131971\n",
      "Large Condition Number 35191251972131971\n",
      "Autocorrelation Failure: 35191251972131971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4480a3cabc1b>:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ze=1/np.sqrt(specobj.ivar['z'][spectrum])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Condition Number 35191259383465992\n",
      "Autocorrelation Failure: 35191259383465992\n",
      "Autocorrelation Failure: 35191255675700437\n",
      "Autocorrelation Failure: 35191259379272137\n",
      "Large Condition Number 35191259383466412\n",
      "Autocorrelation Failure: 35191259383466412\n",
      "Large Condition Number 35191266723497299\n",
      "Autocorrelation Failure: 35191266723497299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4480a3cabc1b>:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  re=1/np.sqrt(specobj.ivar['r'][spectrum])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Condition Number 35191259370884513\n",
      "Autocorrelation Failure: 35191259370884513\n",
      "Outside initial priors 35191273979642609\n",
      "Large Condition Number 35191284691895977\n",
      "Autocorrelation Failure: 35191284691895977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4480a3cabc1b>:24: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  be=1/np.sqrt(specobj.ivar['b'][spectrum])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Condition Number 35191291734132813\n",
      "Autocorrelation Failure: 35191291734132813\n",
      "Large Condition Number 35191281160291793\n",
      "Autocorrelation Failure: 35191281160291793\n",
      "Autocorrelation Failure: 35191291746714758\n",
      "Large Condition Number 35191291746714911\n",
      "Autocorrelation Failure: 35191291746714911\n",
      "Large Condition Number 35191277586744103\n",
      "Autocorrelation Failure: 35191277586744103\n",
      "Large Condition Number 35191281168681049\n",
      "Autocorrelation Failure: 35191281168681049\n",
      "Autocorrelation Failure: 35191281168681049\n",
      "Large Condition Number 35191281168681049\n",
      "Autocorrelation Failure: 35191281168681049\n",
      "Autocorrelation Failure: 35191281168681049\n",
      "Outside initial priors 35191281168681049\n",
      "Large Condition Number 35191274004808475\n",
      "Autocorrelation Failure: 35191274004808475\n",
      "Large Condition Number 35191274004808475\n",
      "Autocorrelation Failure: 35191274004808475\n",
      "Autocorrelation Failure: 35191277603523775\n",
      "Large Condition Number 35191281177068220\n",
      "Autocorrelation Failure: 35191281177068220\n",
      "Large Condition Number 35191270389319000\n",
      "Autocorrelation Failure: 35191270389319000\n",
      "Outside initial priors 35191255700866636\n",
      "Autocorrelation Failure: 35191259396048043\n",
      "Outside initial priors 35191259400241770\n",
      "Large Condition Number 35191270372541563\n",
      "Autocorrelation Failure: 35191270372541563\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "max_extra_runs=50\n",
    "\n",
    "in_str='MgII_Doublets_'+tile+'.csv'\n",
    "feature_table=np.genfromtxt(in_str,delimiter=',',dtype=str)\n",
    "\n",
    "#intial fitting setup\n",
    "fitter = modeling.fitting.LevMarLSQFitter()\n",
    "#200 is fairly arbitrary but it allows z to potenitally vary by a couple hundreths (is this sufficent?)\n",
    "sub_region_size=50\n",
    "rest_frame_sep=7.1755\n",
    "    \n",
    "#MCMC setup\n",
    "ndim=7\n",
    "nwalkers = 32\n",
    "    \n",
    "for feature in feature_table:\n",
    "    #will need a better way to record date and tile, probably in Doublet.csv\n",
    "    x_spc,y_flx,y_err=get_spec(feature[0],tile,date)\n",
    "\n",
    "    #determine redshift and appropriate line_sep\n",
    "    z=float(feature[1])\n",
    "    line_sep=rest_frame_sep*(1+z)\n",
    "    peak=int(feature[2])\n",
    "\n",
    "    #set sub region values, bounded by [0,x_spc-1]\n",
    "    srh=min(len(x_spc)-1,peak+sub_region_size)\n",
    "    srl=max(0,peak-sub_region_size)\n",
    "\n",
    "    #determine max and min z in window (or lowest/highest values possible if at edge of wavelength space)\n",
    "    z_low=x_spc[srl]/2795.5301-1\n",
    "    z_high=x_spc[srh]/2795.5301-1\n",
    "\n",
    "    #define subregion in x and y\n",
    "    reg_wave=x_spc[srl:srh]\n",
    "    reg_flx=y_flx[srl:srh]\n",
    "    reg_err=y_err[srl:srh]\n",
    "    \n",
    "    #initial line guesses\n",
    "    init_m=(reg_flx[0]-reg_flx[-1])/(reg_wave[0]-reg_wave[-1])\n",
    "    init_b=reg_flx[0]\n",
    "    \n",
    "    init_Amp1= -float(feature[5])\n",
    "    init_Amp2= -float(feature[7])\n",
    "    \n",
    "    init_StdDev1= float(feature[6])\n",
    "    init_StdDev2= float(feature[8])\n",
    "\n",
    "    #define initial theta (TODO: Reconsider guesses for m,b)\n",
    "    initial=[z,init_Amp1,init_Amp2,init_StdDev1,init_StdDev2,init_m,init_b]\n",
    "    #could widen this inital guess range, don't think it matters though\n",
    "    \n",
    "    p0 = initial + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "    #run sampler (region)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=[reg_wave,reg_flx,reg_err,z_low,z_high])\n",
    "    #burn-in\n",
    "    state = sampler.run_mcmc(p0, 100)\n",
    "    sampler.reset()\n",
    "    #initial production\n",
    "    state=sampler.run_mcmc(state, 5000)\n",
    "    \n",
    "    #extra production runs if we haven't reached autocorrelation\n",
    "    extra_runs=0\n",
    "    while(extra_runs<max_extra_runs):\n",
    "        #should probably make this not a try/except but no idea how. MCMC docs\n",
    "        try:\n",
    "            sampler.get_autocorr_time(discard=1000)\n",
    "            break\n",
    "        except:\n",
    "            extra_runs+=1\n",
    "            try:\n",
    "                state=sampler.run_mcmc(state,1000)\n",
    "            except:\n",
    "                extra_runs=max_extra_runs\n",
    "                print('Large Condition Number',feature[0])\n",
    "    if(extra_runs==max_extra_runs):\n",
    "        print('Autocorrelation Failure:',feature[0])\n",
    "        '''fig, axes = plt.subplots(7, figsize=(10, 7), sharex=True)\n",
    "        samples = sampler.get_chain()\n",
    "        labels = [\"z\", \"Amp1\", \"Amp2\",\"StdDev1\",\"StdDev2\",\"m\",\"b\"]\n",
    "        for i in range(ndim):\n",
    "            ax = axes[i]\n",
    "            ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "            ax.set_xlim(0, len(samples))\n",
    "            ax.set_ylabel(labels[i])\n",
    "            ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "        axes[-1].set_xlabel(\"step number\")''';\n",
    "        continue\n",
    "\n",
    "    #extract MCMC info, discard 500 is fairly random\n",
    "    flat_samples = sampler.get_chain(flat=True,discard=1000)\n",
    "    mean_accept_frac=np.mean(sampler.acceptance_fraction)\n",
    "    \n",
    "    out_str='MgII_Candidate_Chains/'+feature[0]+'_'+str(np.percentile(flat_samples[:, 0],50))+'.csv'\n",
    "    #Save Chain to output csv for plotting\n",
    "    if(mean_accept_frac>0.0):\n",
    "        np.savetxt(out_str, flat_samples, delimiter=\",\")\n",
    "    else:\n",
    "        print('Outside initial priors',feature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI developer",
   "language": "python",
   "name": "desi-developer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
