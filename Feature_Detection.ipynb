{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DESI_SPECTRO_REDUX=/global/cfs/cdirs/desi/spectro/redux\n",
      "env: SPECPROD=andes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import desispec.io\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy import modeling\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "#using the commissioning targeting mask\n",
    "from desitarget.cmx.cmx_targetmask import cmx_mask\n",
    "from desitarget.targets import main_cmx_or_sv\n",
    "\n",
    "%set_env DESI_SPECTRO_REDUX=/global/cfs/cdirs/desi/spectro/redux\n",
    "%set_env SPECPROD=andes\n",
    "reduxdir = desispec.io.specprod_root()\n",
    "\n",
    "tile='68000'\n",
    "date='20200314'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn 'b', 'r', 'z' into 'brz'\n",
    "def quick_brz(specobj,spectrum):\n",
    "    #pull wavelength sections\n",
    "    bw=np.round(specobj.wave['b'],3)\n",
    "    rw=np.round(specobj.wave['r'],3)\n",
    "    zw=np.round(specobj.wave['z'],3)\n",
    "    \n",
    "    #find overlapping arrays in wave\n",
    "    br_overlap=np.intersect1d(bw,rw)\n",
    "    rz_overlap=np.intersect1d(rw,zw)\n",
    "\n",
    "    #find indices of overlapping regions\n",
    "    br_start=int(np.where(bw==br_overlap[0])[0])\n",
    "    br_end=int(len(bw))\n",
    "\n",
    "    rz_start=int(np.where(rw==rz_overlap[0])[0])\n",
    "    rz_end=int(len(rw))\n",
    "\n",
    "    #pull flux\n",
    "    bf=specobj.flux['b'][spectrum]\n",
    "    rf=specobj.flux['r'][spectrum]\n",
    "    zf=specobj.flux['z'][spectrum]\n",
    "    #pull error\n",
    "    be=1/np.sqrt(specobj.ivar['b'][spectrum])\n",
    "    re=1/np.sqrt(specobj.ivar['r'][spectrum])\n",
    "    ze=1/np.sqrt(specobj.ivar['z'][spectrum])\n",
    "    #turn into 'brz'\n",
    "    x_spc=np.concatenate((bw[:br_start],(bw[br_start:br_end]+rw[:br_end-br_start])/2,rw[br_end-br_start:rz_start],(rw[rz_start:rz_end]+zw[:rz_end-rz_start])/2,zw[rz_end-rz_start:]))\n",
    "    y_flx=np.concatenate((bf[:br_start],(bf[br_start:br_end]+rf[:br_end-br_start])/2,rf[br_end-br_start:rz_start],(rf[rz_start:rz_end]+zf[:rz_end-rz_start])/2,zf[rz_end-rz_start:]))\n",
    "    y_err=np.concatenate((be[:br_start],(be[br_start:br_end]+re[:br_end-br_start])/2,re[br_end-br_start:rz_start],(re[rz_start:rz_end]+ze[:rz_end-rz_start])/2,ze[rz_end-rz_start:]))\n",
    "    \n",
    "    return(x_spc,y_flx,y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Peakfinder function.\n",
    "Inputs: data - array of values in which to find peaks\n",
    "        err  - array of associated error values to data\n",
    "        threshold - level of standard deviation required to be defined as a peak\n",
    "Description:\n",
    "        Detects peaks in a 1d array with associated errors. First determines mean and standard deviation (std)\n",
    "        in 2000 index window around each index, then checks if the associated value is greater than mean+err+threshold*std.\n",
    "        If the value is then the value and its location in the array are appended to the output peaks array.\n",
    "Outputs:\n",
    "        peaks - 1d array holding locations of detected peaks\n",
    "\n",
    "''';\n",
    "def find_p(data,threshold,edge_clip=30,window_size=1000):\n",
    "    #initialize output array\n",
    "    peaks=[]\n",
    "    \n",
    "    #pad data array with 1 values (data is currently pased as a ratio of fit/signal)\n",
    "    data=(np.pad(data[edge_clip:-edge_clip],window_size,mode='constant',constant_values=1))\n",
    "    \n",
    "    #iterate over array length\n",
    "    for i in range(1000,len(data)):\n",
    "        #find windowed median and std\n",
    "        median=np.median(data[i-window_size:i+window_size])\n",
    "        #std=np.std(data[i-window_size:i+window_size])\n",
    "        #remove massive outliers (points where flux gets right near 0)\n",
    "        #these points are still considered for peaks, but not factored into std\n",
    "        std=np.std(data[i-window_size:i+window_size]<np.std(data)*20)\n",
    "            \n",
    "        #check if peak conditions are true\n",
    "        if(data[i]>median+threshold*std and data[i]==np.max(data[i-5:i+5])):\n",
    "            #append true location of peak pre padding\n",
    "            peaks.append(i-window_size+edge_clip)\n",
    "            #append value of peak\n",
    "            \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from itertools import *\n",
    "fitter = modeling.fitting.LevMarLSQFitter()\n",
    "model = modeling.models.Gaussian1D()\n",
    "\n",
    "#whole thing can probably use a rewrite for the sake of efficency\n",
    "def doublet_finder(targetid,continuum,data,y_err,x_spc,min_z):\n",
    "    rf_line_sep=7.1755\n",
    "    #may want to adjust this down if too many matches\n",
    "    #I think this is what does most of the sample cutting\n",
    "    rf_err_margain=0.6\n",
    "    \n",
    "    residual=continuum-data\n",
    "    peaks=np.asarray(find_p(continuum/data,5.0),dtype=int)\n",
    "    \n",
    "    #Generate groups of data with positive residuals\n",
    "    #From https://stackoverflow.com/questions/3149440/python-splitting-list-based-on-missing-numbers-in-a-sequence\n",
    "    groups = []\n",
    "    for k, g in groupby(enumerate(np.where(residual>0)[0]), lambda x: x[0]-x[1]):\n",
    "        groups.append(list(map(itemgetter(1), g)))\n",
    "    absorb_lines=[]\n",
    "    for group in groups:\n",
    "        #Skip groups of 1 or 2 data vals, these aren't worthwhile peaks and cause an issue in fitting\n",
    "        if(len(group) < 3):\n",
    "            continue\n",
    "        \n",
    "        peak=np.intersect1d(peaks,group)\n",
    "        if(len(peak)==0):\n",
    "            continue\n",
    "        else:\n",
    "            peak=int(np.mean(peak))\n",
    "        \n",
    "        #calculate snr, seperate class for high signal\n",
    "        if(np.average(group)<5):\n",
    "            snr=np.sum(residual[group]/continuum[group])/np.sqrt(np.sum(y_err[group]**2))\n",
    "        else:\n",
    "            snr=np.sum(residual[group]/1)/np.sqrt(np.sum(y_err[group]**2))\n",
    "\n",
    "        #this 3 threshold is mutable, experiment around I guess?\n",
    "        if(snr>3.5):\n",
    "            #Fit gaussian model\n",
    "            model = modeling.models.Gaussian1D(amplitude=np.nanmax(residual[group]),mean=np.average(x_spc[group]))\n",
    "            fm = fitter(model=model, x=x_spc[group], y=residual[group])\n",
    "            #determine redshift by model params\n",
    "            \n",
    "            cen=fm.parameters[1]\n",
    "            #z=x_spc[peak]/2795.5301-1\n",
    "            \n",
    "            if(cen/2795.5301-1>min_z):\n",
    "                absorb_lines.append([cen,group,snr,fm.parameters[0],fm.parameters[2],peak])\n",
    "    \n",
    "    doublets=[]\n",
    "    for line1 in absorb_lines:\n",
    "        z=line1[0]/2795.5301-1\n",
    "        line_sep=rf_line_sep*(1+z)\n",
    "        err_margain=rf_err_margain*(1+z)\n",
    "\n",
    "        for line2 in absorb_lines:\n",
    "            if(line1[0]+line_sep-err_margain<line2[0]<line1[0]+line_sep+err_margain):\n",
    "                #pass along the redshift of first line, redshift diff to second line, and both SNRs\n",
    "                doublets.append([str(targetid),z,line1[5],line1[2],line2[2],line1[3],line1[4],line2[3],line2[4]])\n",
    "    return doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-4480a3cabc1b>:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ze=1/np.sqrt(specobj.ivar['z'][spectrum])\n",
      "<ipython-input-19-306329786cbe>:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  peaks=np.asarray(find_p(continuum/data,5.0),dtype=int)\n",
      "<ipython-input-17-4480a3cabc1b>:24: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  be=1/np.sqrt(specobj.ivar['b'][spectrum])\n",
      "<ipython-input-17-4480a3cabc1b>:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  re=1/np.sqrt(specobj.ivar['r'][spectrum])\n",
      "<ipython-input-19-306329786cbe>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  peaks=np.asarray(find_p(continuum/data,5.0),dtype=int)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "cnt=0\n",
    "#good_candidates = np.genfromtxt('Spec_w_goodCandidates.txt',dtype=str)\n",
    "#run over all spectrographs\n",
    "for s in range(0,10):\n",
    "    tile, date, spectrograph = tile, date, str(s)\n",
    "    #can adapt to forming dir name more cleanly\n",
    "    dirn = os.path.join(reduxdir, \"tiles\", tile, date)\n",
    "    #dirname = os.path.join(os.getenv(\"DESI_SPECTRO_REDUX\"), os.getenv(\"SPECPROD\"), \"tiles\", tile, date)\n",
    "    fn = \"coadd-{}-{}-{}.fits\".format(spectrograph, tile, date)\n",
    "    \n",
    "    #open coadd spectrum and zbest files, will want to ope h5 file at some point\n",
    "    specfile = os.path.join(dirn, fn)\n",
    "    zbestfile=specfile.replace('coadd', 'zbest')\n",
    "\n",
    "    #read them in using std method\n",
    "    specobj = desispec.io.read_spectra(specfile)\n",
    "    zbest = Table.read(zbestfile, hdu=1)\n",
    "    #grab targetids, ra, dec and z\n",
    "    fm = specobj.target_ids()\n",
    "    ra = specobj.fibermap['TARGET_RA']\n",
    "    dec =specobj.fibermap['TARGET_DEC']\n",
    "    redshifts=zbest['Z']\n",
    "    #extract all sources that were targeted as SV-like quasars\n",
    "    qsos = np.where(specobj.fibermap[\"CMX_TARGET\"] & cmx_mask[\"SV0_QSO\"])[0]\n",
    "    #print(qsos)\n",
    "    #run over all spectra\n",
    "    for i in qsos:\n",
    "        spectrum = i\n",
    "        targetid=fm[i]\n",
    "        \n",
    "        min_z=(1216*(1+redshifts[i])/2795.5301)-1\n",
    "        #define x_range and flux_vals\n",
    "        #see if \"brz\" is given\n",
    "        if(\"brz\" in specobj.wave):\n",
    "            x_spc = specobj.wave[\"brz\"]\n",
    "            y_flx = specobj.flux[\"brz\"][spectrum]\n",
    "            y_err=1/np.sqrt(specobj.ivar[\"brz\"][spectrum])\n",
    "        #else combine into \"brz\" using helper fnc.\n",
    "        else:\n",
    "            x_spc,y_flx,y_err=quick_brz(specobj,spectrum)\n",
    "            \n",
    "        #estimate continuum using median filter\n",
    "        cont_est = medfilt(y_flx,19)\n",
    "        #calculate residual\n",
    "        bc_residual = cont_est-y_flx\n",
    "\n",
    "        doublets=doublet_finder(str(targetid),cont_est,y_flx,y_err,x_spc,min_z)\n",
    "\n",
    "        for i in doublets:\n",
    "            results.append(i)\n",
    "out_str='MgII_Doublets_'+tile+'.csv'\n",
    "np.savetxt(out_str, results, delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI developer",
   "language": "python",
   "name": "desi-developer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
